{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d9c5009",
   "metadata": {},
   "source": [
    "# Ableton LLM Control"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c8132d",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b8294f",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51cc72a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "\n",
    "import ipywidgets as widgets\n",
    "import live\n",
    "import numpy as np\n",
    "import sounddevice as sd\n",
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    WhisperForConditionalGeneration,\n",
    "    WhisperProcessor,\n",
    "    pipeline,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc5df65",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e0eacb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT_CLASSIFIER_MODEL_NAME = \"ableton_osc_matcher\"\n",
    "TEXT_CLASSIFIER_MODEL_PATH = f\"../artifacts/{TEXT_CLASSIFIER_MODEL_NAME}_trained\"\n",
    "CONFIDENCE_THRESHOLD = 0.5\n",
    "# DEVICE = (\n",
    "#     \"mps\"\n",
    "#     if hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available()\n",
    "#     else \"cpu\"\n",
    "# )\n",
    "INPUT_CHANNELS = 1\n",
    "SAMPLE_RATE = 16_000  # Whisper sample rate\n",
    "MAX_FRAMES = 5 * SAMPLE_RATE  # Max recording time\n",
    "\n",
    "sd.default.samplerate = SAMPLE_RATE\n",
    "sd.default.channels = INPUT_CHANNELS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4211269",
   "metadata": {},
   "source": [
    "## Voice recording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e4492a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_recording() -> np.ndarray:\n",
    "    return np.zeros((MAX_FRAMES, INPUT_CHANNELS))\n",
    "\n",
    "def start_recording() -> np.ndarray:\n",
    "    recording = init_recording()\n",
    "    sd.rec(out=recording)\n",
    "    return recording\n",
    "\n",
    "def trim_recording(recording: np.ndarray) -> np.ndarray:\n",
    "    last_non_zero = np.max(np.where(recording.any(axis=1))[0]) + 1\n",
    "    return recording[:last_non_zero]\n",
    "\n",
    "def stop_recording(out: np.ndarray) -> np.ndarray:\n",
    "    sd.stop()\n",
    "    return trim_recording(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b384cbd",
   "metadata": {},
   "source": [
    "## Voice transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "801d750e",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = WhisperProcessor.from_pretrained(\"openai/whisper-tiny.en\")\n",
    "speech_recognition_model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-tiny.en\")\n",
    "transcriber = pipeline(\"automatic-speech-recognition\", model=speech_recognition_model, tokenizer=processor.tokenizer, feature_extractor=processor.feature_extractor)\n",
    "\n",
    "def transcribe(recording: np.ndarray) -> str:\n",
    "    result = transcriber(recording.squeeze())[\"text\"].strip()\n",
    "    print(f\"[Transcriber]: {result}\")\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7932d7a2",
   "metadata": {},
   "source": [
    "## Text classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "798371d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_classifier_model = AutoModelForSequenceClassification.from_pretrained(TEXT_CLASSIFIER_MODEL_PATH)\n",
    "tokenizer = AutoTokenizer.from_pretrained(TEXT_CLASSIFIER_MODEL_PATH)\n",
    "classifier = pipeline(\"text-classification\", model=text_classifier_model, tokenizer=tokenizer)\n",
    "\n",
    "def classify_text(command: str) -> str:\n",
    "    results: list[dict] = classifier(command)\n",
    "    result = results[0]\n",
    "    print(f\"[Classifier]: {result}\")\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a93db2d",
   "metadata": {},
   "source": [
    "## Ableton Live connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "06fada9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Live]: ok\n"
     ]
    }
   ],
   "source": [
    "livequery = live.Query()\n",
    "test_response = livequery.query(\"/live/test\")\n",
    "print(f\"[Live]: {test_response[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4c80b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_PARAMETERS = {\n",
    "    \"/live/song/create_audio_track\": [-1],\n",
    "    \"/live/song/create_midi_track\": [-1],\n",
    "    \"/live/song/create_return_track\": [-1],\n",
    "    \"/live/song/create_scene\": [-1],\n",
    "}\n",
    "\n",
    "def get_parameters(osc_endpoint: str) -> list[Any]:\n",
    "    return DEFAULT_PARAMETERS.get(osc_endpoint, [])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e910dd",
   "metadata": {},
   "source": [
    "## Full pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d34b4cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(recording: np.ndarray) -> None:\n",
    "    command = transcribe(recording)\n",
    "    classification = classify_text(command)\n",
    "    if classification[\"score\"] < CONFIDENCE_THRESHOLD:\n",
    "        print(\"[Classifier] Low confidence\")\n",
    "        return\n",
    "    osc_endpoint = classification[\"label\"]\n",
    "    if osc_endpoint == \"none\":\n",
    "        print(\"[Live] No matching endpoint\")\n",
    "        return\n",
    "    parameters = get_parameters(osc_endpoint)\n",
    "    live_result = livequery.cmd(osc_endpoint, *parameters)\n",
    "    if live_result is not None:\n",
    "        print(f\"[Live]: {live_result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be251e1e",
   "metadata": {},
   "source": [
    "## User interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1140d93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b35dfa2820a4c2fa7d1972ed981cc32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='danger', description='Record', icon='microphone', style=ButtonStyle(), tooltip='Record')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Transcriber]: New MIDI track.\n",
      "[Classifier]: {'label': '/live/song/create_midi_track', 'score': 0.7960658669471741}\n",
      "[Transcriber]: Play scene.\n",
      "[Classifier]: {'label': '/live/view/start_listen/selected_scene', 'score': 0.8248885869979858}\n",
      "[Transcriber]: Play scene.\n",
      "[Classifier]: {'label': '/live/view/start_listen/selected_scene', 'score': 0.8248885869979858}\n",
      "[Transcriber]: Play scene.\n",
      "[Classifier]: {'label': '/live/view/start_listen/selected_scene', 'score': 0.8248885869979858}\n",
      "[Transcriber]: Stop playing.\n",
      "[Classifier]: {'label': '/live/song/stop_playing', 'score': 0.4330361783504486}\n",
      "[Classifier] Low confidence\n",
      "[Transcriber]: Start playing.\n",
      "[Classifier]: {'label': '/live/song/continue_playing', 'score': 0.46374908089637756}\n",
      "[Classifier] Low confidence\n",
      "[Transcriber]: From the top.\n",
      "[Classifier]: {'label': '/live/song/start_playing', 'score': 0.9426731467247009}\n",
      "[Transcriber]: Hose?\n",
      "[Classifier]: {'label': 'none', 'score': 0.9755275249481201}\n",
      "[Live] No matching endpoint\n",
      "[Transcriber]: Still?\n",
      "[Classifier]: {'label': 'none', 'score': 0.9750480055809021}\n",
      "[Live] No matching endpoint\n",
      "[Transcriber]: Stop.\n",
      "[Classifier]: {'label': '/live/song/stop_playing', 'score': 0.7795167565345764}\n",
      "[Transcriber]: New order you truck.\n",
      "[Classifier]: {'label': 'none', 'score': 0.9650993943214417}\n",
      "[Live] No matching endpoint\n",
      "[Transcriber]: New Audio Track.\n",
      "[Classifier]: {'label': '/live/song/create_audio_track', 'score': 0.778803288936615}\n",
      "[Transcriber]: Undo.\n",
      "[Classifier]: {'label': '/live/song/undo', 'score': 0.8502156138420105}\n",
      "[Transcriber]: Undo.\n",
      "[Classifier]: {'label': '/live/song/undo', 'score': 0.8502156138420105}\n",
      "[Transcriber]: Let's try that again.\n",
      "[Classifier]: {'label': '/live/song/start_playing', 'score': 0.7555059194564819}\n",
      "[Transcriber]: We do.\n",
      "[Classifier]: {'label': 'none', 'score': 0.9713724255561829}\n",
      "[Live] No matching endpoint\n",
      "[Transcriber]: Redo\n",
      "[Classifier]: {'label': '/live/song/redo', 'score': 0.6527646780014038}\n",
      "[Transcriber]: Do that again.\n",
      "[Classifier]: {'label': '/live/song/start_playing', 'score': 0.5393933057785034}\n",
      "[Transcriber]: Read it.\n",
      "[Classifier]: {'label': 'none', 'score': 0.20088663697242737}\n",
      "[Classifier] Low confidence\n",
      "[Transcriber]: Redo!\n",
      "[Classifier]: {'label': '/live/song/redo', 'score': 0.6384232044219971}\n",
      "[Transcriber]: Undo.\n",
      "[Classifier]: {'label': '/live/song/undo', 'score': 0.8502156138420105}\n",
      "[Transcriber]: new MIDI track.\n",
      "[Classifier]: {'label': '/live/song/create_midi_track', 'score': 0.7960658669471741}\n",
      "[Transcriber]: We do.\n",
      "[Classifier]: {'label': 'none', 'score': 0.9713724255561829}\n",
      "[Live] No matching endpoint\n",
      "[Transcriber]: I'll redo that.\n",
      "[Classifier]: {'label': '/live/song/redo', 'score': 0.602838397026062}\n",
      "[Transcriber]: Do do do do\n",
      "[Classifier]: {'label': 'none', 'score': 0.6175199747085571}\n",
      "[Live] No matching endpoint\n",
      "[Transcriber]: Stop!\n",
      "[Classifier]: {'label': '/live/song/stop_playing', 'score': 0.5292999744415283}\n"
     ]
    }
   ],
   "source": [
    "recording = init_recording()\n",
    "\n",
    "button = widgets.Button(\n",
    "    description=\"Record\",\n",
    "    disabled=False,\n",
    "    button_style=\"danger\",\n",
    "    tooltip=\"Record\",\n",
    "    icon=\"microphone\",\n",
    ")\n",
    "\n",
    "def on_click(b: widgets.Button) -> None:\n",
    "    global recording\n",
    "    if b.description == \"Record\":\n",
    "        b.description = \"Done\"\n",
    "        b.tooltip = \"Done\"\n",
    "        b.button_style = \"warning\"\n",
    "        b.icon = \"microphone-slash\"\n",
    "        recording = start_recording()\n",
    "    else:\n",
    "        b.description = \"Record\"\n",
    "        b.tooltip = \"Record\"\n",
    "        b.button_style = \"danger\"\n",
    "        b.icon = \"microphone\"\n",
    "        b.disabled = True\n",
    "        recording = stop_recording(recording)\n",
    "        b.disabled = False\n",
    "        run(recording)\n",
    "\n",
    "button.on_click(on_click)\n",
    "button"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7bc7e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# result = livequery.cmd(\"/live/song/create_return_track\")\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8721ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
